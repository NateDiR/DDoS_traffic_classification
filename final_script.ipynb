{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -fs\n",
    "import pandas as pd\n",
    "import  numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score, confusion_matrix\n",
    "from dask import dataframe as dd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "COLOR = 'white'\n",
    "mpl.rcParams['text.color'] = COLOR\n",
    "mpl.rcParams['axes.labelcolor'] = COLOR\n",
    "mpl.rcParams['xtick.color'] = COLOR\n",
    "mpl.rcParams['ytick.color'] = COLOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf = dd.read_csv(r\"C:\\Users\\nated\\Downloads\\CSV-01-12\\01-12\\DrDoS_LDAP.csv\", dtype={'SimillarHTTP': 'object'},blocksize='64MB')\n",
    "df = ddf.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(df['Label'].value_counts()) / len(df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['FlowID', 'SourceIP', 'DestinationIP', 'Timestamp', 'SimillarHTTP', 'SourcePort', 'DestinationPort'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.drop(columns=['Label']).columns.tolist()\n",
    "for col in cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.get_dummies(df['Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Label\"], axis=1)\n",
    "y = labels.BENIGN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, stratify=y_train_val, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(\n",
    "    std.fit_transform(X_train),\n",
    "    columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(processes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = pd.DataFrame(std.transform(X_val), columns = X_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = lr.predict(X_val_scaled)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_confusion = confusion_matrix(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in lr_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in lr_confusion.flatten()/np.sum(lr_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(lr_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Logistic Regression Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_ps = np.linspace(0.01,0.99,101)\n",
    "model_val_probs = lr.predict_proba(X_val_scaled)[:,1] # positive class probs, same basic logistic model we fit in section 2 \n",
    "\n",
    "fbeta_scores, prec_scores, rec_scores, acc_scores = [], [], [], []\n",
    "for p in thresh_ps:\n",
    "    model_val_labels = model_val_probs >= p\n",
    "    fbeta_scores.append(fbeta_score(y_val, model_val_labels, beta=2))    \n",
    "    prec_scores.append(precision_score(y_val, model_val_labels))\n",
    "    rec_scores.append(recall_score(y_val, model_val_labels))\n",
    "    acc_scores.append(accuracy_score(y_val, model_val_labels))\n",
    "    \n",
    "plt.plot(thresh_ps, fbeta_scores)\n",
    "plt.plot(thresh_ps, prec_scores)\n",
    "plt.plot(thresh_ps, rec_scores)\n",
    "plt.plot(thresh_ps, acc_scores)\n",
    "\n",
    "plt.title('Metric Scores vs. Positive Class Decision Probability Threshold')\n",
    "plt.legend(['F Beta 2','Precision','Recall','Accuracy'], bbox_to_anchor=(1.05, 0), loc='lower left')\n",
    "plt.xlabel('P threshold')\n",
    "plt.ylabel('Metric score')\n",
    "\n",
    "best_fbeta_score = np.max(fbeta_scores) \n",
    "best_thresh_p_fbeta = thresh_ps[np.argmax(fbeta_scores)]\n",
    "best_recall_score = np.max(rec_scores)\n",
    "best_thresh_p_rec = thresh_ps[np.argmax(rec_scores)]\n",
    "best_prec_score = np.max(prec_scores)\n",
    "best_thresh_p_prec = thresh_ps[np.argmax(prec_scores)]\n",
    "\n",
    "print('Logistic Regression Model best F Beta2 score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_fbeta_score, best_thresh_p_fbeta))\n",
    "print('Logistic Regression Model best recall score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_recall_score, best_thresh_p_rec))\n",
    "print('Logistic Regression Model best precision score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_recall_score, best_thresh_p_prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(\n",
    "    std.fit_transform(X_train),\n",
    "    columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression(solver='lbfgs', max_iter=1000000, n_jobs=-1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    lr2.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = pd.DataFrame(std.transform(X_val), columns = X_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = lr2.predict(X_val_scaled)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_confusion = confusion_matrix(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in lr2_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in lr2_confusion.flatten()/np.sum(lr2_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(lr2_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Weighted Logistic Regression Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_ps = np.linspace(0.01,0.99,101)\n",
    "model_val_probs = lr2.predict_proba(X_val_scaled)[:,1] # positive class probs, same basic logistic model we fit in section 2 \n",
    "\n",
    "fbeta_scores, prec_scores, rec_scores, acc_scores = [], [], [], []\n",
    "for p in thresh_ps:\n",
    "    model_val_labels = model_val_probs >= p\n",
    "    fbeta_scores.append(fbeta_score(y_val, model_val_labels, beta=2))    \n",
    "    prec_scores.append(precision_score(y_val, model_val_labels))\n",
    "    rec_scores.append(recall_score(y_val, model_val_labels))\n",
    "    acc_scores.append(accuracy_score(y_val, model_val_labels))\n",
    "    \n",
    "plt.plot(thresh_ps, fbeta_scores)\n",
    "plt.plot(thresh_ps, prec_scores)\n",
    "plt.plot(thresh_ps, rec_scores)\n",
    "plt.plot(thresh_ps, acc_scores)\n",
    "\n",
    "plt.title('Metric Scores vs. Positive Class Decision Probability Threshold')\n",
    "plt.legend(['F Beta 2','Precision','Recall','Accuracy'], bbox_to_anchor=(1.05, 0), loc='lower left')\n",
    "plt.xlabel('P threshold')\n",
    "plt.ylabel('Metric score')\n",
    "\n",
    "best_fbeta_score = np.max(fbeta_scores) \n",
    "best_thresh_p_fbeta = thresh_ps[np.argmax(fbeta_scores)]\n",
    "best_recall_score = np.max(rec_scores)\n",
    "best_thresh_p_rec = thresh_ps[np.argmax(rec_scores)]\n",
    "best_prec_score = np.max(prec_scores)\n",
    "best_thresh_p_prec = thresh_ps[np.argmax(prec_scores)]\n",
    "\n",
    "print('Balanced Logistic Regression Model best F Beta2 score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_fbeta_score, best_thresh_p_fbeta))\n",
    "print('Balanced Logistic Regression Model best recall score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_recall_score, best_thresh_p_rec))\n",
    "print('Balanced Logistic Regression Model best precision score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_recall_score, best_thresh_p_prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = rf.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_confusion = confusion_matrix(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in rf_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in rf_confusion.flatten()/np.sum(rf_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(rf_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Random Forest Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=4, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = rf2.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2_confusion = confusion_matrix(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in rf2_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in rf2_confusion.flatten()/np.sum(rf2_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(rf2_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Weighted Random Forest Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3 = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=5, class_weight='balanced_subsample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    rf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = rf3.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3_confusion = confusion_matrix(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in rf3_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in rf3_confusion.flatten()/np.sum(rf3_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(rf3_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Random Forest With Bootstrap Class Weighting Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_rf = BalancedRandomForestClassifier(n_estimators=1000, random_state=6, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    imb_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = imb_rf.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_rf_confusion = confusion_matrix(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in imb_rf_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in imb_rf_confusion.flatten()/np.sum(imb_rf_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(imb_rf_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Random Forest with Data Resampling Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_rf2 = BalancedRandomForestClassifier(n_estimators=1000, random_state=7, class_weight='balanced', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    imb_rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = imb_rf2.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_rf2_confusion = confusion_matrix(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in imb_rf2_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in imb_rf2_confusion.flatten()/np.sum(imb_rf2_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(imb_rf2_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Random Forest with Data Resampling (Balanced Class Weight) Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_rf3 = BalancedRandomForestClassifier(n_estimators=1000, random_state=8, class_weight='balanced_subsample', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    imb_rf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = imb_rf3.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_rf3_confusion = confusion_matrix(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in imb_rf3_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in imb_rf3_confusion.flatten()/np.sum(imb_rf3_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(imb_rf3_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Random Forest with Data Resampling (Bootstrap Class Weighting) Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm = xgb.XGBClassifier(\n",
    "                        n_estimators=100000,\n",
    "                        max_depth=6,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        learning_rate=.1,\n",
    "                        subsample=1,\n",
    "                        scale_pos_weight=99,\n",
    "                        min_child_weight=1,\n",
    "                        colsample_bytree=1,\n",
    "                        tree_method='gpu_hist',\n",
    "                        use_label_encoder=False\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set=[(X_train,y_train),(X_val,y_val)] \n",
    "fit_model = gbm.fit( \n",
    "                    X_train, y_train, \n",
    "                    eval_set=eval_set,\n",
    "                    eval_metric='auc',\n",
    "                    early_stopping_rounds=20,\n",
    "                    verbose=True \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = gbm.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_confusion = confusion_matrix(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in gbm_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in gbm_confusion.flatten()/np.sum(gbm_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(gbm_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('XGBoost Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8,11))\n",
    "xgb.plot_importance(gbm, ax=ax)\n",
    "fig,ax2 = plt.subplots(figsize=(8,11))\n",
    "xgb.plot_importance(gbm, importance_type='gain', ax=ax2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.get_booster().get_score(importance_type='weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.get_booster().get_score(importance_type='gain')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm2 = xgb.XGBClassifier(\n",
    "                        n_estimators=100000,\n",
    "                        max_depth=20,\n",
    "                        objective=\"binary:logistic\",\n",
    "                        learning_rate=.1,\n",
    "                        subsample=1,\n",
    "                        scale_pos_weight=99,\n",
    "                        min_child_weight=1,\n",
    "                        colsample_bytree=1,\n",
    "                        tree_method='gpu_hist',\n",
    "                        use_label_encoder=False,\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_set=[(X_train,y_train),(X_val,y_val)] \n",
    "fit_model = gbm2.fit( \n",
    "                    X_train, y_train, \n",
    "                    eval_set=eval_set,\n",
    "                    eval_metric='auc',\n",
    "                    early_stopping_rounds=20,\n",
    "                    verbose=True \n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm2.best_ntree_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = gbm2.predict(X_val, iteration_range=(1,26))\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm2_confusion = confusion_matrix(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in gbm2_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in gbm2_confusion.flatten()/np.sum(gbm2_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(gbm2_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('XGBoost2 Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = [\"lr2\", \"rf\", \"imb_rf3\", \"gbm\"]\n",
    "\n",
    "model_vars = [eval(n) for n in model_names]\n",
    "model_list = list(zip(model_names, model_vars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier = VotingClassifier(estimators=model_list,\n",
    "                                    voting='hard',\n",
    "                                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = voting_classifier.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_classifier_confusion = confusion_matrix(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in voting_classifier_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in voting_classifier_confusion.flatten()/np.sum(voting_classifier_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(voting_classifier_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Voting Classifier Ensemble Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_voting_classifier = VotingClassifier(estimators=model_list,\n",
    "                                    voting='soft',\n",
    "                                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_voting_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = soft_voting_classifier.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft_voting_classifier_confusion = confusion_matrix(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in soft_voting_classifier_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in soft_voting_classifier_confusion.flatten()/np.sum(soft_voting_classifier_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(soft_voting_classifier_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Soft Voting Classifier Ensemble Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked = StackingClassifier(estimators=model_list, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    stacked.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = stacked.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_voting_confusion = confusion_matrix(y_val, y_val_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in stacked_voting_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in stacked_voting_confusion.flatten()/np.sum(stacked_voting_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(stacked_voting_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Stacked Classifier Ensemble Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_preds = stacked.predict(X_test)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_test, y_test_preds), recall_score(y_test, y_test_preds), fbeta_score(y_test, y_test_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_voting_confusion_test = confusion_matrix(y_test, y_test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in stacked_voting_confusion_test.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in stacked_voting_confusion_test.flatten()/np.sum(stacked_voting_confusion_test)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(stacked_voting_confusion_test,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Stacked Classifier Ensemble Confusion Matrix - Test Set');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_ps = np.linspace(0.01,0.99,101)\n",
    "model_test_probs = stacked.predict_proba(X_test)[:,1] # positive class probs, same basic logistic model we fit in section 2 \n",
    "\n",
    "fbeta_scores, prec_scores, rec_scores, acc_scores = [], [], [], []\n",
    "for p in thresh_ps:\n",
    "    model_val_labels = model_test_probs >= p\n",
    "    fbeta_scores.append(fbeta_score(y_val, model_val_labels, beta=2))    \n",
    "    prec_scores.append(precision_score(y_val, model_val_labels))\n",
    "    rec_scores.append(recall_score(y_val, model_val_labels))\n",
    "    acc_scores.append(accuracy_score(y_val, model_val_labels))\n",
    "    \n",
    "plt.plot(thresh_ps, fbeta_scores)\n",
    "plt.plot(thresh_ps, prec_scores)\n",
    "plt.plot(thresh_ps, rec_scores)\n",
    "plt.plot(thresh_ps, acc_scores)\n",
    "\n",
    "plt.title('Metric Scores vs. Positive Class Decision Probability Threshold')\n",
    "plt.legend(['F Beta 2','Precision','Recall','Accuracy'], bbox_to_anchor=(1.05, 0), loc='lower left')\n",
    "plt.xlabel('P threshold')\n",
    "plt.ylabel('Metric score')\n",
    "\n",
    "best_fbeta_score = np.max(fbeta_scores) \n",
    "best_thresh_p_fbeta = thresh_ps[np.argmax(fbeta_scores)]\n",
    "best_recall_score = np.max(rec_scores)\n",
    "best_thresh_p_rec = thresh_ps[np.argmax(rec_scores)]\n",
    "best_prec_score = np.max(prec_scores)\n",
    "best_thresh_p_prec = thresh_ps[np.argmax(prec_scores)]\n",
    "\n",
    "print('Logistic Regression Model best F Beta2 score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_fbeta_score, best_thresh_p_fbeta))\n",
    "print('Logistic Regression Model best recall score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_recall_score, best_thresh_p_rec))\n",
    "print('Logistic Regression Model best precision score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_recall_score, best_thresh_p_prec))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37bcb6fee63730fa93d2e9179a784cea588943ad44a0d8b70e0d0ff7fbf414ce"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
