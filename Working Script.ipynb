{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7939999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -fs\n",
    "import pandas as pd\n",
    "import  numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, fbeta_score\n",
    "from dask import dataframe as dd\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.options.mode.use_inf_as_na = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0df4e0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dask !!!\n",
    "ddf = dd.read_csv(r\"C:\\Users\\nated\\Downloads\\CSV-01-12\\01-12\\DrDoS_LDAP.csv\", dtype={'SimillarHTTP': 'object'},blocksize='64MB')\n",
    "df = ddf.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78f5641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.replace(' ', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "281d7372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DrDoS_LDAP    99.926107\n",
       "BENIGN         0.073893\n",
       "Name: Label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df['Label'].value_counts()) / len(df) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7613d3bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['FlowID', 'SourceIP', 'DestinationIP', 'Timestamp', 'SimillarHTTP', 'SourcePort', 'DestinationPort'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03eeb5e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c7206f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = df.drop(columns=['Label']).columns.tolist()\n",
    "for col in cols:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "657986d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2dd6d0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=[\"Label\"], axis=1)\n",
    "y = df['Label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "058b060b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_e = LabelEncoder()\n",
    "y = l_e.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d5f8404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression(solver='lbfgs', max_iter=1000000, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efea42d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2d32f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=.25, stratify=y_train_val, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00ebd190",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(\n",
    "    std.fit_transform(X_train),\n",
    "    columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce7de809",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(processes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8356e756",
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    lr.fit(X_train_scaled, y_train)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcbd8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, fbeta_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8767cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = pd.DataFrame(std.transform(X_val), columns = X_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff64824",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = lr.predict(X_val_scaled)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3824b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_confusion = confusion_matrix(y_val, y_val_preds, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2230e845",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in lr_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in lr_confusion.flatten()/np.sum(lr_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abfd9257",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(lr_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Logistic Regression Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a956dfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_ps = np.linspace(0.01,0.99,101)\n",
    "model_val_probs = lr.predict_proba(X_val_scaled)[:,1] # positive class probs, same basic logistic model we fit in section 2 \n",
    "\n",
    "fbeta_scores, prec_scores, rec_scores, acc_scores = [], [], [], []\n",
    "for p in thresh_ps:\n",
    "    model_val_labels = model_val_probs >= p\n",
    "    fbeta_scores.append(fbeta_score(y_val, model_val_labels, beta=2))    \n",
    "    prec_scores.append(precision_score(y_val, model_val_labels))\n",
    "    rec_scores.append(recall_score(y_val, model_val_labels))\n",
    "    acc_scores.append(accuracy_score(y_val, model_val_labels))\n",
    "    \n",
    "plt.plot(thresh_ps, fbeta_scores)\n",
    "plt.plot(thresh_ps, prec_scores)\n",
    "plt.plot(thresh_ps, rec_scores)\n",
    "plt.plot(thresh_ps, acc_scores)\n",
    "\n",
    "plt.title('Metric Scores vs. Positive Class Decision Probability Threshold')\n",
    "plt.legend(['F Beta 2','Precision','Recall','Accuracy'], bbox_to_anchor=(1.05, 0), loc='lower left')\n",
    "plt.xlabel('P threshold')\n",
    "plt.ylabel('Metric score')\n",
    "\n",
    "best_fbeta_score = np.max(fbeta_scores) \n",
    "best_thresh_p_fbeta = thresh_ps[np.argmax(fbeta_scores)]\n",
    "best_recall_score = np.max(rec_scores)\n",
    "best_thresh_p_rec = thresh_ps[np.argmax(rec_scores)]\n",
    "best_prec_score = np.max(prec_scores)\n",
    "best_thresh_p_prec = thresh_ps[np.argmax(prec_scores)]\n",
    "\n",
    "print('Logistic Regression Model best F Beta2 score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_fbeta_score, best_thresh_p_fbeta))\n",
    "print('Logistic Regression Model best recall score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_recall_score, best_thresh_p_rec))\n",
    "print('Logistic Regression Model best precision score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_recall_score, best_thresh_p_prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f4c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0561e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ad327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = pd.DataFrame(\n",
    "    std.fit_transform(X_train),\n",
    "    columns = X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c49a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2 = LogisticRegression(solver='lbfgs', max_iter=1000000, n_jobs=-1, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423789bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    lr2.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cbd53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val_scaled = pd.DataFrame(std.transform(X_val), columns = X_val.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a270695",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = lr2.predict(X_val_scaled)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4dd087",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr2_confusion = confusion_matrix(y_val, y_val_preds, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6283a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in lr2_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in lr2_confusion.flatten()/np.sum(lr2_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4072dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(lr2_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Weighted Logistic Regression Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2c9be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh_ps = np.linspace(0.01,0.99,101)\n",
    "model_val_probs = lr2.predict_proba(X_val_scaled)[:,1] # positive class probs, same basic logistic model we fit in section 2 \n",
    "\n",
    "fbeta_scores, prec_scores, rec_scores, acc_scores = [], [], [], []\n",
    "for p in thresh_ps:\n",
    "    model_val_labels = model_val_probs >= p\n",
    "    fbeta_scores.append(fbeta_score(y_val, model_val_labels, beta=2))    \n",
    "    prec_scores.append(precision_score(y_val, model_val_labels))\n",
    "    rec_scores.append(recall_score(y_val, model_val_labels))\n",
    "    acc_scores.append(accuracy_score(y_val, model_val_labels))\n",
    "    \n",
    "plt.plot(thresh_ps, fbeta_scores)\n",
    "plt.plot(thresh_ps, prec_scores)\n",
    "plt.plot(thresh_ps, rec_scores)\n",
    "plt.plot(thresh_ps, acc_scores)\n",
    "\n",
    "plt.title('Metric Scores vs. Positive Class Decision Probability Threshold')\n",
    "plt.legend(['F Beta 2','Precision','Recall','Accuracy'], bbox_to_anchor=(1.05, 0), loc='lower left')\n",
    "plt.xlabel('P threshold')\n",
    "plt.ylabel('Metric score')\n",
    "\n",
    "best_fbeta_score = np.max(fbeta_scores) \n",
    "best_thresh_p_fbeta = thresh_ps[np.argmax(fbeta_scores)]\n",
    "best_recall_score = np.max(rec_scores)\n",
    "best_thresh_p_rec = thresh_ps[np.argmax(rec_scores)]\n",
    "best_prec_score = np.max(prec_scores)\n",
    "best_thresh_p_prec = thresh_ps[np.argmax(prec_scores)]\n",
    "\n",
    "print('Balanced Logistic Regression Model best F Beta2 score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_fbeta_score, best_thresh_p_fbeta))\n",
    "print('Balanced Logistic Regression Model best recall score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_recall_score, best_thresh_p_rec))\n",
    "print('Balanced Logistic Regression Model best precision score %.3f at prob decision threshold >= %.3f' \n",
    "      % (best_recall_score, best_thresh_p_prec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614d36ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989f4c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0561e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38de0f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19fae147",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = rf.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4dd087",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_confusion = confusion_matrix(y_val, y_val_preds, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf115e0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in rf_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in rf_confusion.flatten()/np.sum(rf_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1e6949",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(rf_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Random Forest Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e758e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=4, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704826fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0838351",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ec795",
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = rf2.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d249e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf2_confusion = confusion_matrix(y_val, y_val_preds, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b21dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in rf2_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in rf2_confusion.flatten()/np.sum(rf2_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d24c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(rf2_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Weighted Random Forest Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e758e0c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3 = RandomForestClassifier(n_estimators=1000, n_jobs=-1, random_state=5, class_weight='balanced_subsample')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704826fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0838351",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ec795",
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    rf3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = rf3.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d249e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf3_confusion = confusion_matrix(y_val, y_val_preds, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b21dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in rf3_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in rf3_confusion.flatten()/np.sum(rf3_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d24c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(rf3_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Random Forest With Bootstrap Class Weighting Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a2756",
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_rf = BalancedRandomForestClassifier(n_estimators=1000, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704826fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=6, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0838351",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ec795",
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    imb_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = imb_rf.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d249e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_rf_confusion = confusion_matrix(y_val, y_val_preds, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b21dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in imb_rf_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in imb_rf_confusion.flatten()/np.sum(imb_rf_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d24c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(imb_rf_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Random Forest with Data Resampling Confusion Matrix');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548a2756",
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_rf2 = BalancedRandomForestClassifier(n_estimators=1000, random_state=7, class_weight='balanced')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "704826fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size = .2, stratify=y, random_state=7, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0838351",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size = .25, stratify=y_train_val, random_state=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00ec795",
   "metadata": {},
   "outputs": [],
   "source": [
    "with joblib.parallel_backend(\"dask\"):\n",
    "    imb_rf2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caec38b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_preds = imb_rf2.predict(X_val)\n",
    "print(\"Precision: {}, Recall: {}, F2 Score: {}\".format(precision_score(y_val, y_val_preds), recall_score(y_val, y_val_preds), fbeta_score(y_val, y_val_preds, beta=2.0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95d249e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imb_rf2_confusion = confusion_matrix(y_val, y_val_preds, labels=[1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b21dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_names = ['True Neg', 'False Pos', 'False Neg', 'True Pos']\n",
    "group_counts = [\"{0:0.0f}\".format(value) for value in imb_rf2_confusion.flatten()]\n",
    "group_percentages = [\"{0:0.4%}\".format(value) for value in imb_rf2_confusion.flatten()/np.sum(imb_rf2_confusion)]\n",
    "labels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\n",
    "labels = np.asarray(labels).reshape(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d24c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(imb_rf2_confusion,cmap='rocket_r', annot=labels, fmt='', square=True, xticklabels=['DrDoS_LDAP', 'Benign'], yticklabels=['DrDoS_LDAP', 'Benign'])\n",
    "plt.xlabel('Predicted Traffic Type')\n",
    "plt.ylabel('Actual Traffic Type')\n",
    "plt.title('Random Forest with Data Resampling (Balanced Class Weight) Confusion Matrix');"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
